# Calibration Run `cal_1770590048` — Deep Assessment
**Date:** 2026-02-08 14:23–14:33 PST | **Reviewer:** Claw (subagent) | **20 poses completed**

---

## ⚠️ Critical Finding: Checkerboard Was NOT Covered

Despite the intent to run "with the checkerboard pattern covered this time," **all 20 calibration frames still show both checkerboard patterns prominently visible** — one propped up vertically on the left and one flat on the table surface. I examined frames 1, 4, 5, 8, 10, 13, 15, 18, and 20 — every single one has the checkerboard fully in-frame.

The live camera snapshots (taken after the run) show a person actively covering the checkerboard with white paper towels/cloth *now*, suggesting the covering happened post-run, not before it. **This run has the same checkerboard contamination problem as the previous run (`cal_1770588119`).**

---

## 1. Frame Analysis — What I See

### Camera Perspective
All 20 frames are from a **single overhead/bird's-eye camera**. This is likely camera 1 (the better-performing camera from the previous run). No camera 0 (front-facing) frames appear to be in the /tmp set, though the calibration_data.json confirms both cameras captured each pose.

### Arm Visibility
- The arm (Unitree D1, black multi-jointed manipulator) is **clearly visible to human eyes** in every frame
- The circular base, main links, and end-effector with blue-tipped gripper fingers are identifiable
- The arm is mounted on an OSB/plywood board in the center of the workspace

### Pose Variety
Examining the commanded angles across 20 poses, there's good diversity:
- **Base rotation:** -60° to +60° (poses 17, 18)
- **Shoulder:** -60° to +30° (poses 4, 11)
- **Elbow:** -45° to +60° (poses 6, 19)
- **Wrist pitch:** -45° to +45° (poses 15, 16)
- **Multi-joint combos:** Several poses combine 3-4 joint movements (poses 8, 12, 13, 19)

However, from the overhead view, **many poses look very similar**. The bird's-eye perspective compresses depth, making shoulder and elbow flexion (which move in the vertical plane) hard to distinguish visually. Base rotation is the most visible change. Frames 4 vs 5 vs 10 vs 15 are hard to tell apart from overhead.

### Segmentability
**Moderate difficulty.** The black arm has reasonable contrast against the lighter plywood base and white paper surfaces. However:
- Where the arm crosses over the checkerboard, the black links blend into black squares
- The uniformly dark arm makes it hard to distinguish individual joints without markers
- The cluttered background (boxes, steering wheel, monitors, bucket) creates false edges

---

## 2. Lighting Assessment

- **Source:** Overhead workshop lighting (fluorescent/LED) — even, diffuse illumination
- **Quality:** Adequate — no harsh directional shadows, no extreme contrast
- **Issues:**
  - Mild specular reflections on concrete floor and some equipment
  - The arm's dark matte surface doesn't produce strong highlights that could aid joint detection
  - Softbox studio lights are visible in the scene (right side) but appear to be OFF — these could improve illumination significantly if turned on
- **Verdict:** Lighting is *acceptable* but not optimized. The softboxes should be used.

---

## 3. Comparison with Previous Run (`cal_1770588119`)

### What Improved
The new run's `full_comparison.json` shows **dramatic improvement in LLM detection**:

| Metric | Previous Run | This Run (`cal_1770590048`) |
|--------|-------------|---------------------------|
| LLM detection rate | 0% (never called) | **100%** (40/40 calls) |
| CV detection rate | 1.5% (3/200) | **10%** (4/40) |
| LLM tokens used | 0 | 102,999 |
| Avg tokens/call | 0 | 2,575 |
| Total detections | 3 | 40 |

**Key progress:**
- The LLM pipeline is now **fully functional** — 100% detection rate across all poses and cameras
- CV detection improved from 1.5% to 10% (still low, but 6.7× better)
- The system is producing usable joint position estimates via LLM

### What Didn't Change
- Checkerboard still present (same visual contamination)
- Arm still has no markers
- Workspace still cluttered
- Camera intrinsics likely still placeholder values (not verified in this run's data)

---

## 4. Joint Control Accuracy

Motor control remains **excellent** — consistent with the previous run:
- All joints within ±0.8° of commanded angles
- Cross-coupling minimal (non-primary joints drift <1°)
- Joint 6 (gripper rotation) shows occasional offset (e.g., -2.4° at pose 0) but this is typical

The arm hardware is not the bottleneck. The servo accuracy is more than sufficient for pick-and-place.

---

## 5. Workspace Readiness for Red Bull Can Pick

### Current State
The workspace is **not ready** for object detection/pick-and-place:
- Checkerboard patterns dominate the table surface — no clear "pick zone"
- Cluttered with measuring tape, L-square ruler, blue tape, and other calibration tools
- No Red Bull can visible in any frame
- The plywood mounting board provides limited clean workspace around the arm's reach

### What's Needed
- Clear the table surface of calibration materials
- Place Red Bull can in a defined pick zone within arm reach
- Ensure contrasting background (the white paper towels being placed now would work well)
- A simple color-based detector could find the Red Bull can (distinctive blue/silver/red cylindrical shape)

---

## 6. Realistic Path to Vision-Guided Pick-and-Place

### Priority 1: Fix Camera Calibration (Blocking)
1. **Calibrate camera intrinsics** using the checkerboard (OpenCV `calibrateCamera`) — do this FIRST, as a separate step
2. **Then remove/cover the checkerboard** and run arm calibration
3. Target: <1px reprojection error (currently 90-139px with placeholder values)

### Priority 2: Add Visual Markers to Arm (High Impact)
- Colored tape or ArUco markers on each joint would boost CV detection from 10% to potentially 80%+
- Even simple colored dots (distinct color per joint) would be transformative
- The gripper's blue tips are the most detectable part — that principle should extend to all joints

### Priority 3: Clean the Workspace (Medium Impact)
- Remove checkerboard, tools, and clutter from the arm's workspace
- Lay down a uniform contrasting background (white paper/cloth is good)
- Place the Red Bull can in a defined position

### Priority 4: Optimize Camera Setup (Medium Impact)
- **Turn on the softbox lights** visible in the scene
- Consider adding a side-view camera (camera 0) at 45° angle — the overhead-only view loses depth info
- Verify camera 0 is actually usable or reposition it

### Priority 5: Leverage LLM Detection (Already Working)
- LLM detection at 100% is a major win — use this as the primary joint detection method
- CV can supplement for speed (LLM at 2,575 tokens/call is expensive)
- Build the pick-and-place pipeline using LLM detection first, optimize with CV later

### Estimated Timeline to Working Pick-and-Place
1. **Camera intrinsics calibration** — 30 min
2. **Workspace cleanup + checkerboard removal** — 15 min (happening now)
3. **Re-run arm calibration without checkerboard** — 10 min
4. **Add joint markers + re-run** — 20 min
5. **Red Bull can detection** — 1-2 hours (color segmentation + pose estimation)
6. **Pick-and-place integration** — 2-4 hours (motion planning, grasp strategy, error handling)

**Total: ~4-7 hours of focused work** from current state to a working demo.

---

## Summary

| Aspect | Rating | Notes |
|--------|--------|-------|
| Checkerboard covered? | ❌ No | Still visible in all 20 frames — being covered NOW, post-run |
| Arm motor control | ✅ Excellent | ±0.8° accuracy, not the bottleneck |
| LLM detection | ✅ Working | 100% rate — major improvement over previous 0% |
| CV detection | ⚠️ Poor | 10% — needs markers and clean background |
| Camera calibration | ❌ Likely bad | Probably still placeholder intrinsics |
| Pose diversity | ✅ Good | 20 varied poses covering full joint ranges |
| Pose distinguishability | ⚠️ Fair | Overhead view compresses depth; base rotation most visible |
| Workspace cleanliness | ❌ Not ready | Checkerboard + clutter; no Red Bull can in scene |
| Lighting | ⚠️ Adequate | Softboxes available but not turned on |

**Bottom line:** This run fixed the LLM pipeline (huge win — 0% → 100%). The checkerboard was not actually covered, so a re-run is needed. The immediate next steps are: (1) finish covering the checkerboard, (2) calibrate camera intrinsics properly, (3) add joint markers, (4) re-run. The arm works great and LLM detection works great — the remaining gaps are workspace prep and CV optimization.
